# [No.1] construct_wrapper.112
# In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(62)/
funcgraph fg_112(
        %para1 : Tensor(F64)[4, 128]    # q
        , %para2 : Tensor(F64)[4, 17625]    # a
        , %para3 : Tensor(F64)[4, 3, 224, 224]    # img
        , %para4 : Ref[Tensor(F32)][64, 3, 3, 3]    # net.image_channel.simple_cnn.0.weight
        , %para5 : Ref[Tensor(F32)][64]    # net.image_channel.simple_cnn.1.gamma
        , %para6 : Ref[Tensor(F32)][64]    # net.image_channel.simple_cnn.1.beta
        , %para7 : Ref[Tensor(F32)][128, 64, 3, 3]    # net.image_channel.simple_cnn.4.weight
        , %para8 : Ref[Tensor(F32)][128]    # net.image_channel.simple_cnn.5.gamma
        , %para9 : Ref[Tensor(F32)][128]    # net.image_channel.simple_cnn.5.beta
        , %para10 : Ref[Tensor(F32)][256, 128, 3, 3]    # net.image_channel.simple_cnn.8.weight
        , %para11 : Ref[Tensor(F32)][256]    # net.image_channel.simple_cnn.9.gamma
        , %para12 : Ref[Tensor(F32)][256]    # net.image_channel.simple_cnn.9.beta
        , %para13 : Ref[Tensor(F32)][768, 256, 3, 3]    # net.image_channel.simple_cnn.12.weight
        , %para14 : Ref[Tensor(F32)][30522, 768]    # net.ques_channel.embeddings.word_embeddings.embedding_table
        , %para15 : Ref[Tensor(F32)][512, 768]    # net.ques_channel.embeddings.position_embeddings.embedding_table
        , %para16 : Ref[Tensor(F32)][2, 768]    # net.ques_channel.embeddings.token_type_embeddings.embedding_table
        , %para17 : Ref[Tensor(F32)][768]    # net.ques_channel.embeddings.layer_norm.gamma
        , %para18 : Ref[Tensor(F32)][768]    # net.ques_channel.embeddings.layer_norm.beta
        , %para19 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.0.attention.self_attn.query.weight
        , %para20 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.0.attention.self_attn.query.bias
        , %para21 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.0.attention.self_attn.key.weight
        , %para22 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.0.attention.self_attn.key.bias
        , %para23 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.0.attention.self_attn.value.weight
        , %para24 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.0.attention.self_attn.value.bias
        , %para25 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.0.attention.output.dense.weight
        , %para26 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.0.attention.output.dense.bias
        , %para27 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.0.attention.output.layer_norm.gamma
        , %para28 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.0.attention.output.layer_norm.beta
        , %para29 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.0.intermediate.dense.weight
        , %para30 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.0.intermediate.dense.bias
        , %para31 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.0.output.dense.weight
        , %para32 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.0.output.dense.bias
        , %para33 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.0.output.layer_norm.gamma
        , %para34 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.0.output.layer_norm.beta
        , %para35 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.1.attention.self_attn.query.weight
        , %para36 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.1.attention.self_attn.query.bias
        , %para37 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.1.attention.self_attn.key.weight
        , %para38 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.1.attention.self_attn.key.bias
        , %para39 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.1.attention.self_attn.value.weight
        , %para40 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.1.attention.self_attn.value.bias
        , %para41 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.1.attention.output.dense.weight
        , %para42 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.1.attention.output.dense.bias
        , %para43 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.1.attention.output.layer_norm.gamma
        , %para44 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.1.attention.output.layer_norm.beta
        , %para45 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.1.intermediate.dense.weight
        , %para46 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.1.intermediate.dense.bias
        , %para47 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.1.output.dense.weight
        , %para48 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.1.output.dense.bias
        , %para49 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.1.output.layer_norm.gamma
        , %para50 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.1.output.layer_norm.beta
        , %para51 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.2.attention.self_attn.query.weight
        , %para52 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.2.attention.self_attn.query.bias
        , %para53 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.2.attention.self_attn.key.weight
        , %para54 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.2.attention.self_attn.key.bias
        , %para55 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.2.attention.self_attn.value.weight
        , %para56 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.2.attention.self_attn.value.bias
        , %para57 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.2.attention.output.dense.weight
        , %para58 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.2.attention.output.dense.bias
        , %para59 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.2.attention.output.layer_norm.gamma
        , %para60 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.2.attention.output.layer_norm.beta
        , %para61 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.2.intermediate.dense.weight
        , %para62 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.2.intermediate.dense.bias
        , %para63 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.2.output.dense.weight
        , %para64 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.2.output.dense.bias
        , %para65 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.2.output.layer_norm.gamma
        , %para66 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.2.output.layer_norm.beta
        , %para67 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.3.attention.self_attn.query.weight
        , %para68 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.3.attention.self_attn.query.bias
        , %para69 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.3.attention.self_attn.key.weight
        , %para70 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.3.attention.self_attn.key.bias
        , %para71 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.3.attention.self_attn.value.weight
        , %para72 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.3.attention.self_attn.value.bias
        , %para73 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.3.attention.output.dense.weight
        , %para74 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.3.attention.output.dense.bias
        , %para75 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.3.attention.output.layer_norm.gamma
        , %para76 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.3.attention.output.layer_norm.beta
        , %para77 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.3.intermediate.dense.weight
        , %para78 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.3.intermediate.dense.bias
        , %para79 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.3.output.dense.weight
        , %para80 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.3.output.dense.bias
        , %para81 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.3.output.layer_norm.gamma
        , %para82 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.3.output.layer_norm.beta
        , %para83 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.4.attention.self_attn.query.weight
        , %para84 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.4.attention.self_attn.query.bias
        , %para85 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.4.attention.self_attn.key.weight
        , %para86 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.4.attention.self_attn.key.bias
        , %para87 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.4.attention.self_attn.value.weight
        , %para88 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.4.attention.self_attn.value.bias
        , %para89 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.4.attention.output.dense.weight
        , %para90 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.4.attention.output.dense.bias
        , %para91 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.4.attention.output.layer_norm.gamma
        , %para92 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.4.attention.output.layer_norm.beta
        , %para93 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.4.intermediate.dense.weight
        , %para94 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.4.intermediate.dense.bias
        , %para95 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.4.output.dense.weight
        , %para96 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.4.output.dense.bias
        , %para97 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.4.output.layer_norm.gamma
        , %para98 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.4.output.layer_norm.beta
        , %para99 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.5.attention.self_attn.query.weight
        , %para100 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.5.attention.self_attn.query.bias
        , %para101 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.5.attention.self_attn.key.weight
        , %para102 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.5.attention.self_attn.key.bias
        , %para103 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.5.attention.self_attn.value.weight
        , %para104 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.5.attention.self_attn.value.bias
        , %para105 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.5.attention.output.dense.weight
        , %para106 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.5.attention.output.dense.bias
        , %para107 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.5.attention.output.layer_norm.gamma
        , %para108 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.5.attention.output.layer_norm.beta
        , %para109 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.5.intermediate.dense.weight
        , %para110 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.5.intermediate.dense.bias
        , %para111 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.5.output.dense.weight
        , %para112 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.5.output.dense.bias
        , %para113 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.5.output.layer_norm.gamma
        , %para114 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.5.output.layer_norm.beta
        , %para115 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.6.attention.self_attn.query.weight
        , %para116 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.6.attention.self_attn.query.bias
        , %para117 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.6.attention.self_attn.key.weight
        , %para118 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.6.attention.self_attn.key.bias
        , %para119 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.6.attention.self_attn.value.weight
        , %para120 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.6.attention.self_attn.value.bias
        , %para121 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.6.attention.output.dense.weight
        , %para122 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.6.attention.output.dense.bias
        , %para123 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.6.attention.output.layer_norm.gamma
        , %para124 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.6.attention.output.layer_norm.beta
        , %para125 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.6.intermediate.dense.weight
        , %para126 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.6.intermediate.dense.bias
        , %para127 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.6.output.dense.weight
        , %para128 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.6.output.dense.bias
        , %para129 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.6.output.layer_norm.gamma
        , %para130 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.6.output.layer_norm.beta
        , %para131 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.7.attention.self_attn.query.weight
        , %para132 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.7.attention.self_attn.query.bias
        , %para133 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.7.attention.self_attn.key.weight
        , %para134 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.7.attention.self_attn.key.bias
        , %para135 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.7.attention.self_attn.value.weight
        , %para136 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.7.attention.self_attn.value.bias
        , %para137 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.7.attention.output.dense.weight
        , %para138 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.7.attention.output.dense.bias
        , %para139 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.7.attention.output.layer_norm.gamma
        , %para140 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.7.attention.output.layer_norm.beta
        , %para141 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.7.intermediate.dense.weight
        , %para142 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.7.intermediate.dense.bias
        , %para143 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.7.output.dense.weight
        , %para144 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.7.output.dense.bias
        , %para145 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.7.output.layer_norm.gamma
        , %para146 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.7.output.layer_norm.beta
        , %para147 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.8.attention.self_attn.query.weight
        , %para148 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.8.attention.self_attn.query.bias
        , %para149 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.8.attention.self_attn.key.weight
        , %para150 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.8.attention.self_attn.key.bias
        , %para151 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.8.attention.self_attn.value.weight
        , %para152 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.8.attention.self_attn.value.bias
        , %para153 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.8.attention.output.dense.weight
        , %para154 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.8.attention.output.dense.bias
        , %para155 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.8.attention.output.layer_norm.gamma
        , %para156 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.8.attention.output.layer_norm.beta
        , %para157 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.8.intermediate.dense.weight
        , %para158 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.8.intermediate.dense.bias
        , %para159 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.8.output.dense.weight
        , %para160 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.8.output.dense.bias
        , %para161 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.8.output.layer_norm.gamma
        , %para162 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.8.output.layer_norm.beta
        , %para163 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.9.attention.self_attn.query.weight
        , %para164 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.9.attention.self_attn.query.bias
        , %para165 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.9.attention.self_attn.key.weight
        , %para166 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.9.attention.self_attn.key.bias
        , %para167 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.9.attention.self_attn.value.weight
        , %para168 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.9.attention.self_attn.value.bias
        , %para169 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.9.attention.output.dense.weight
        , %para170 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.9.attention.output.dense.bias
        , %para171 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.9.attention.output.layer_norm.gamma
        , %para172 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.9.attention.output.layer_norm.beta
        , %para173 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.9.intermediate.dense.weight
        , %para174 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.9.intermediate.dense.bias
        , %para175 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.9.output.dense.weight
        , %para176 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.9.output.dense.bias
        , %para177 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.9.output.layer_norm.gamma
        , %para178 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.9.output.layer_norm.beta
        , %para179 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.10.attention.self_attn.query.weight
        , %para180 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.10.attention.self_attn.query.bias
        , %para181 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.10.attention.self_attn.key.weight
        , %para182 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.10.attention.self_attn.key.bias
        , %para183 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.10.attention.self_attn.value.weight
        , %para184 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.10.attention.self_attn.value.bias
        , %para185 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.10.attention.output.dense.weight
        , %para186 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.10.attention.output.dense.bias
        , %para187 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.10.attention.output.layer_norm.gamma
        , %para188 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.10.attention.output.layer_norm.beta
        , %para189 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.10.intermediate.dense.weight
        , %para190 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.10.intermediate.dense.bias
        , %para191 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.10.output.dense.weight
        , %para192 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.10.output.dense.bias
        , %para193 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.10.output.layer_norm.gamma
        , %para194 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.10.output.layer_norm.beta
        , %para195 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.11.attention.self_attn.query.weight
        , %para196 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.11.attention.self_attn.query.bias
        , %para197 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.11.attention.self_attn.key.weight
        , %para198 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.11.attention.self_attn.key.bias
        , %para199 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.11.attention.self_attn.value.weight
        , %para200 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.11.attention.self_attn.value.bias
        , %para201 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.encoder.layer.11.attention.output.dense.weight
        , %para202 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.11.attention.output.dense.bias
        , %para203 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.11.attention.output.layer_norm.gamma
        , %para204 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.11.attention.output.layer_norm.beta
        , %para205 : Ref[Tensor(F32)][3072, 768]    # net.ques_channel.encoder.layer.11.intermediate.dense.weight
        , %para206 : Ref[Tensor(F32)][3072]    # net.ques_channel.encoder.layer.11.intermediate.dense.bias
        , %para207 : Ref[Tensor(F32)][768, 3072]    # net.ques_channel.encoder.layer.11.output.dense.weight
        , %para208 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.11.output.dense.bias
        , %para209 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.11.output.layer_norm.gamma
        , %para210 : Ref[Tensor(F32)][768]    # net.ques_channel.encoder.layer.11.output.layer_norm.beta
        , %para211 : Ref[Tensor(F32)][768, 768]    # net.ques_channel.pooler.dense.weight
        , %para212 : Ref[Tensor(F32)][768]    # net.ques_channel.pooler.dense.bias
        , %para213 : Ref[Tensor(F32)][512, 768]    # net.san.0.ff_image.weight
        , %para214 : Ref[Tensor(F32)][512]    # net.san.0.ff_image.bias
        , %para215 : Ref[Tensor(F32)][512, 768]    # net.san.0.ff_ques.weight
        , %para216 : Ref[Tensor(F32)][512]    # net.san.0.ff_ques.bias
        , %para217 : Ref[Tensor(F32)][1, 512]    # net.san.0.ff_attention.weight
        , %para218 : Ref[Tensor(F32)][1]    # net.san.0.ff_attention.bias
        , %para219 : Ref[Tensor(F32)][17625, 768]    # net.mlp.1.weight
        , %para220 : Ref[Tensor(F32)][17625]    # net.mlp.1.bias
        , %para221 : Ref[Tensor(F32)][1]    # beta1_power
        , %para222 : Ref[Tensor(F32)][1]    # beta2_power
        , %para223 : Ref[Tensor(F32)][64, 3, 3, 3]    # moment1.image_channel.simple_cnn.0.weight
        , %para224 : Ref[Tensor(F32)][64]    # moment1.image_channel.simple_cnn.1.gamma
        , %para225 : Ref[Tensor(F32)][64]    # moment1.image_channel.simple_cnn.1.beta
        , %para226 : Ref[Tensor(F32)][128, 64, 3, 3]    # moment1.image_channel.simple_cnn.4.weight
        , %para227 : Ref[Tensor(F32)][128]    # moment1.image_channel.simple_cnn.5.gamma
        , %para228 : Ref[Tensor(F32)][128]    # moment1.image_channel.simple_cnn.5.beta
        , %para229 : Ref[Tensor(F32)][256, 128, 3, 3]    # moment1.image_channel.simple_cnn.8.weight
        , %para230 : Ref[Tensor(F32)][256]    # moment1.image_channel.simple_cnn.9.gamma
        , %para231 : Ref[Tensor(F32)][256]    # moment1.image_channel.simple_cnn.9.beta
        , %para232 : Ref[Tensor(F32)][768, 256, 3, 3]    # moment1.image_channel.simple_cnn.12.weight
        , %para233 : Ref[Tensor(F32)][30522, 768]    # moment1.ques_channel.embeddings.word_embeddings.embedding_table
        , %para234 : Ref[Tensor(F32)][512, 768]    # moment1.ques_channel.embeddings.position_embeddings.embedding_table
        , %para235 : Ref[Tensor(F32)][2, 768]    # moment1.ques_channel.embeddings.token_type_embeddings.embedding_table
        , %para236 : Ref[Tensor(F32)][768]    # moment1.ques_channel.embeddings.layer_norm.gamma
        , %para237 : Ref[Tensor(F32)][768]    # moment1.ques_channel.embeddings.layer_norm.beta
        , %para238 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.0.attention.self_attn.query.weight
        , %para239 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.0.attention.self_attn.query.bias
        , %para240 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.0.attention.self_attn.key.weight
        , %para241 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.0.attention.self_attn.key.bias
        , %para242 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.0.attention.self_attn.value.weight
        , %para243 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.0.attention.self_attn.value.bias
        , %para244 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.0.attention.output.dense.weight
        , %para245 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.0.attention.output.dense.bias
        , %para246 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.0.attention.output.layer_norm.gamma
        , %para247 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.0.attention.output.layer_norm.beta
        , %para248 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.0.intermediate.dense.weight
        , %para249 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.0.intermediate.dense.bias
        , %para250 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.0.output.dense.weight
        , %para251 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.0.output.dense.bias
        , %para252 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.0.output.layer_norm.gamma
        , %para253 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.0.output.layer_norm.beta
        , %para254 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.1.attention.self_attn.query.weight
        , %para255 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.1.attention.self_attn.query.bias
        , %para256 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.1.attention.self_attn.key.weight
        , %para257 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.1.attention.self_attn.key.bias
        , %para258 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.1.attention.self_attn.value.weight
        , %para259 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.1.attention.self_attn.value.bias
        , %para260 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.1.attention.output.dense.weight
        , %para261 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.1.attention.output.dense.bias
        , %para262 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.1.attention.output.layer_norm.gamma
        , %para263 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.1.attention.output.layer_norm.beta
        , %para264 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.1.intermediate.dense.weight
        , %para265 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.1.intermediate.dense.bias
        , %para266 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.1.output.dense.weight
        , %para267 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.1.output.dense.bias
        , %para268 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.1.output.layer_norm.gamma
        , %para269 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.1.output.layer_norm.beta
        , %para270 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.2.attention.self_attn.query.weight
        , %para271 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.2.attention.self_attn.query.bias
        , %para272 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.2.attention.self_attn.key.weight
        , %para273 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.2.attention.self_attn.key.bias
        , %para274 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.2.attention.self_attn.value.weight
        , %para275 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.2.attention.self_attn.value.bias
        , %para276 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.2.attention.output.dense.weight
        , %para277 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.2.attention.output.dense.bias
        , %para278 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.2.attention.output.layer_norm.gamma
        , %para279 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.2.attention.output.layer_norm.beta
        , %para280 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.2.intermediate.dense.weight
        , %para281 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.2.intermediate.dense.bias
        , %para282 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.2.output.dense.weight
        , %para283 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.2.output.dense.bias
        , %para284 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.2.output.layer_norm.gamma
        , %para285 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.2.output.layer_norm.beta
        , %para286 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.3.attention.self_attn.query.weight
        , %para287 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.3.attention.self_attn.query.bias
        , %para288 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.3.attention.self_attn.key.weight
        , %para289 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.3.attention.self_attn.key.bias
        , %para290 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.3.attention.self_attn.value.weight
        , %para291 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.3.attention.self_attn.value.bias
        , %para292 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.3.attention.output.dense.weight
        , %para293 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.3.attention.output.dense.bias
        , %para294 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.3.attention.output.layer_norm.gamma
        , %para295 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.3.attention.output.layer_norm.beta
        , %para296 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.3.intermediate.dense.weight
        , %para297 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.3.intermediate.dense.bias
        , %para298 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.3.output.dense.weight
        , %para299 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.3.output.dense.bias
        , %para300 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.3.output.layer_norm.gamma
        , %para301 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.3.output.layer_norm.beta
        , %para302 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.4.attention.self_attn.query.weight
        , %para303 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.4.attention.self_attn.query.bias
        , %para304 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.4.attention.self_attn.key.weight
        , %para305 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.4.attention.self_attn.key.bias
        , %para306 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.4.attention.self_attn.value.weight
        , %para307 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.4.attention.self_attn.value.bias
        , %para308 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.4.attention.output.dense.weight
        , %para309 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.4.attention.output.dense.bias
        , %para310 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.4.attention.output.layer_norm.gamma
        , %para311 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.4.attention.output.layer_norm.beta
        , %para312 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.4.intermediate.dense.weight
        , %para313 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.4.intermediate.dense.bias
        , %para314 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.4.output.dense.weight
        , %para315 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.4.output.dense.bias
        , %para316 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.4.output.layer_norm.gamma
        , %para317 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.4.output.layer_norm.beta
        , %para318 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.5.attention.self_attn.query.weight
        , %para319 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.5.attention.self_attn.query.bias
        , %para320 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.5.attention.self_attn.key.weight
        , %para321 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.5.attention.self_attn.key.bias
        , %para322 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.5.attention.self_attn.value.weight
        , %para323 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.5.attention.self_attn.value.bias
        , %para324 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.5.attention.output.dense.weight
        , %para325 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.5.attention.output.dense.bias
        , %para326 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.5.attention.output.layer_norm.gamma
        , %para327 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.5.attention.output.layer_norm.beta
        , %para328 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.5.intermediate.dense.weight
        , %para329 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.5.intermediate.dense.bias
        , %para330 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.5.output.dense.weight
        , %para331 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.5.output.dense.bias
        , %para332 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.5.output.layer_norm.gamma
        , %para333 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.5.output.layer_norm.beta
        , %para334 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.6.attention.self_attn.query.weight
        , %para335 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.6.attention.self_attn.query.bias
        , %para336 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.6.attention.self_attn.key.weight
        , %para337 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.6.attention.self_attn.key.bias
        , %para338 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.6.attention.self_attn.value.weight
        , %para339 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.6.attention.self_attn.value.bias
        , %para340 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.6.attention.output.dense.weight
        , %para341 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.6.attention.output.dense.bias
        , %para342 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.6.attention.output.layer_norm.gamma
        , %para343 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.6.attention.output.layer_norm.beta
        , %para344 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.6.intermediate.dense.weight
        , %para345 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.6.intermediate.dense.bias
        , %para346 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.6.output.dense.weight
        , %para347 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.6.output.dense.bias
        , %para348 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.6.output.layer_norm.gamma
        , %para349 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.6.output.layer_norm.beta
        , %para350 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.7.attention.self_attn.query.weight
        , %para351 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.7.attention.self_attn.query.bias
        , %para352 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.7.attention.self_attn.key.weight
        , %para353 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.7.attention.self_attn.key.bias
        , %para354 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.7.attention.self_attn.value.weight
        , %para355 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.7.attention.self_attn.value.bias
        , %para356 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.7.attention.output.dense.weight
        , %para357 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.7.attention.output.dense.bias
        , %para358 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.7.attention.output.layer_norm.gamma
        , %para359 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.7.attention.output.layer_norm.beta
        , %para360 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.7.intermediate.dense.weight
        , %para361 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.7.intermediate.dense.bias
        , %para362 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.7.output.dense.weight
        , %para363 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.7.output.dense.bias
        , %para364 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.7.output.layer_norm.gamma
        , %para365 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.7.output.layer_norm.beta
        , %para366 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.8.attention.self_attn.query.weight
        , %para367 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.8.attention.self_attn.query.bias
        , %para368 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.8.attention.self_attn.key.weight
        , %para369 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.8.attention.self_attn.key.bias
        , %para370 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.8.attention.self_attn.value.weight
        , %para371 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.8.attention.self_attn.value.bias
        , %para372 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.8.attention.output.dense.weight
        , %para373 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.8.attention.output.dense.bias
        , %para374 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.8.attention.output.layer_norm.gamma
        , %para375 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.8.attention.output.layer_norm.beta
        , %para376 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.8.intermediate.dense.weight
        , %para377 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.8.intermediate.dense.bias
        , %para378 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.8.output.dense.weight
        , %para379 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.8.output.dense.bias
        , %para380 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.8.output.layer_norm.gamma
        , %para381 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.8.output.layer_norm.beta
        , %para382 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.9.attention.self_attn.query.weight
        , %para383 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.9.attention.self_attn.query.bias
        , %para384 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.9.attention.self_attn.key.weight
        , %para385 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.9.attention.self_attn.key.bias
        , %para386 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.9.attention.self_attn.value.weight
        , %para387 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.9.attention.self_attn.value.bias
        , %para388 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.9.attention.output.dense.weight
        , %para389 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.9.attention.output.dense.bias
        , %para390 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.9.attention.output.layer_norm.gamma
        , %para391 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.9.attention.output.layer_norm.beta
        , %para392 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.9.intermediate.dense.weight
        , %para393 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.9.intermediate.dense.bias
        , %para394 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.9.output.dense.weight
        , %para395 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.9.output.dense.bias
        , %para396 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.9.output.layer_norm.gamma
        , %para397 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.9.output.layer_norm.beta
        , %para398 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.10.attention.self_attn.query.weight
        , %para399 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.10.attention.self_attn.query.bias
        , %para400 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.10.attention.self_attn.key.weight
        , %para401 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.10.attention.self_attn.key.bias
        , %para402 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.10.attention.self_attn.value.weight
        , %para403 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.10.attention.self_attn.value.bias
        , %para404 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.10.attention.output.dense.weight
        , %para405 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.10.attention.output.dense.bias
        , %para406 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.10.attention.output.layer_norm.gamma
        , %para407 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.10.attention.output.layer_norm.beta
        , %para408 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.10.intermediate.dense.weight
        , %para409 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.10.intermediate.dense.bias
        , %para410 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.10.output.dense.weight
        , %para411 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.10.output.dense.bias
        , %para412 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.10.output.layer_norm.gamma
        , %para413 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.10.output.layer_norm.beta
        , %para414 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.11.attention.self_attn.query.weight
        , %para415 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.11.attention.self_attn.query.bias
        , %para416 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.11.attention.self_attn.key.weight
        , %para417 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.11.attention.self_attn.key.bias
        , %para418 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.11.attention.self_attn.value.weight
        , %para419 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.11.attention.self_attn.value.bias
        , %para420 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.encoder.layer.11.attention.output.dense.weight
        , %para421 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.11.attention.output.dense.bias
        , %para422 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.11.attention.output.layer_norm.gamma
        , %para423 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.11.attention.output.layer_norm.beta
        , %para424 : Ref[Tensor(F32)][3072, 768]    # moment1.ques_channel.encoder.layer.11.intermediate.dense.weight
        , %para425 : Ref[Tensor(F32)][3072]    # moment1.ques_channel.encoder.layer.11.intermediate.dense.bias
        , %para426 : Ref[Tensor(F32)][768, 3072]    # moment1.ques_channel.encoder.layer.11.output.dense.weight
        , %para427 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.11.output.dense.bias
        , %para428 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.11.output.layer_norm.gamma
        , %para429 : Ref[Tensor(F32)][768]    # moment1.ques_channel.encoder.layer.11.output.layer_norm.beta
        , %para430 : Ref[Tensor(F32)][768, 768]    # moment1.ques_channel.pooler.dense.weight
        , %para431 : Ref[Tensor(F32)][768]    # moment1.ques_channel.pooler.dense.bias
        , %para432 : Ref[Tensor(F32)][512, 768]    # moment1.san.0.ff_image.weight
        , %para433 : Ref[Tensor(F32)][512]    # moment1.san.0.ff_image.bias
        , %para434 : Ref[Tensor(F32)][512, 768]    # moment1.san.0.ff_ques.weight
        , %para435 : Ref[Tensor(F32)][512]    # moment1.san.0.ff_ques.bias
        , %para436 : Ref[Tensor(F32)][1, 512]    # moment1.san.0.ff_attention.weight
        , %para437 : Ref[Tensor(F32)][1]    # moment1.san.0.ff_attention.bias
        , %para438 : Ref[Tensor(F32)][17625, 768]    # moment1.mlp.1.weight
        , %para439 : Ref[Tensor(F32)][17625]    # moment1.mlp.1.bias
        , %para440 : Ref[Tensor(F32)][64, 3, 3, 3]    # moment2.image_channel.simple_cnn.0.weight
        , %para441 : Ref[Tensor(F32)][64]    # moment2.image_channel.simple_cnn.1.gamma
        , %para442 : Ref[Tensor(F32)][64]    # moment2.image_channel.simple_cnn.1.beta
        , %para443 : Ref[Tensor(F32)][128, 64, 3, 3]    # moment2.image_channel.simple_cnn.4.weight
        , %para444 : Ref[Tensor(F32)][128]    # moment2.image_channel.simple_cnn.5.gamma
        , %para445 : Ref[Tensor(F32)][128]    # moment2.image_channel.simple_cnn.5.beta
        , %para446 : Ref[Tensor(F32)][256, 128, 3, 3]    # moment2.image_channel.simple_cnn.8.weight
        , %para447 : Ref[Tensor(F32)][256]    # moment2.image_channel.simple_cnn.9.gamma
        , %para448 : Ref[Tensor(F32)][256]    # moment2.image_channel.simple_cnn.9.beta
        , %para449 : Ref[Tensor(F32)][768, 256, 3, 3]    # moment2.image_channel.simple_cnn.12.weight
        , %para450 : Ref[Tensor(F32)][30522, 768]    # moment2.ques_channel.embeddings.word_embeddings.embedding_table
        , %para451 : Ref[Tensor(F32)][512, 768]    # moment2.ques_channel.embeddings.position_embeddings.embedding_table
        , %para452 : Ref[Tensor(F32)][2, 768]    # moment2.ques_channel.embeddings.token_type_embeddings.embedding_table
        , %para453 : Ref[Tensor(F32)][768]    # moment2.ques_channel.embeddings.layer_norm.gamma
        , %para454 : Ref[Tensor(F32)][768]    # moment2.ques_channel.embeddings.layer_norm.beta
        , %para455 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.0.attention.self_attn.query.weight
        , %para456 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.0.attention.self_attn.query.bias
        , %para457 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.0.attention.self_attn.key.weight
        , %para458 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.0.attention.self_attn.key.bias
        , %para459 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.0.attention.self_attn.value.weight
        , %para460 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.0.attention.self_attn.value.bias
        , %para461 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.0.attention.output.dense.weight
        , %para462 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.0.attention.output.dense.bias
        , %para463 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.0.attention.output.layer_norm.gamma
        , %para464 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.0.attention.output.layer_norm.beta
        , %para465 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.0.intermediate.dense.weight
        , %para466 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.0.intermediate.dense.bias
        , %para467 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.0.output.dense.weight
        , %para468 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.0.output.dense.bias
        , %para469 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.0.output.layer_norm.gamma
        , %para470 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.0.output.layer_norm.beta
        , %para471 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.1.attention.self_attn.query.weight
        , %para472 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.1.attention.self_attn.query.bias
        , %para473 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.1.attention.self_attn.key.weight
        , %para474 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.1.attention.self_attn.key.bias
        , %para475 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.1.attention.self_attn.value.weight
        , %para476 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.1.attention.self_attn.value.bias
        , %para477 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.1.attention.output.dense.weight
        , %para478 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.1.attention.output.dense.bias
        , %para479 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.1.attention.output.layer_norm.gamma
        , %para480 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.1.attention.output.layer_norm.beta
        , %para481 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.1.intermediate.dense.weight
        , %para482 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.1.intermediate.dense.bias
        , %para483 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.1.output.dense.weight
        , %para484 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.1.output.dense.bias
        , %para485 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.1.output.layer_norm.gamma
        , %para486 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.1.output.layer_norm.beta
        , %para487 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.2.attention.self_attn.query.weight
        , %para488 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.2.attention.self_attn.query.bias
        , %para489 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.2.attention.self_attn.key.weight
        , %para490 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.2.attention.self_attn.key.bias
        , %para491 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.2.attention.self_attn.value.weight
        , %para492 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.2.attention.self_attn.value.bias
        , %para493 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.2.attention.output.dense.weight
        , %para494 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.2.attention.output.dense.bias
        , %para495 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.2.attention.output.layer_norm.gamma
        , %para496 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.2.attention.output.layer_norm.beta
        , %para497 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.2.intermediate.dense.weight
        , %para498 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.2.intermediate.dense.bias
        , %para499 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.2.output.dense.weight
        , %para500 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.2.output.dense.bias
        , %para501 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.2.output.layer_norm.gamma
        , %para502 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.2.output.layer_norm.beta
        , %para503 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.3.attention.self_attn.query.weight
        , %para504 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.3.attention.self_attn.query.bias
        , %para505 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.3.attention.self_attn.key.weight
        , %para506 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.3.attention.self_attn.key.bias
        , %para507 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.3.attention.self_attn.value.weight
        , %para508 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.3.attention.self_attn.value.bias
        , %para509 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.3.attention.output.dense.weight
        , %para510 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.3.attention.output.dense.bias
        , %para511 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.3.attention.output.layer_norm.gamma
        , %para512 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.3.attention.output.layer_norm.beta
        , %para513 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.3.intermediate.dense.weight
        , %para514 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.3.intermediate.dense.bias
        , %para515 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.3.output.dense.weight
        , %para516 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.3.output.dense.bias
        , %para517 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.3.output.layer_norm.gamma
        , %para518 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.3.output.layer_norm.beta
        , %para519 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.4.attention.self_attn.query.weight
        , %para520 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.4.attention.self_attn.query.bias
        , %para521 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.4.attention.self_attn.key.weight
        , %para522 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.4.attention.self_attn.key.bias
        , %para523 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.4.attention.self_attn.value.weight
        , %para524 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.4.attention.self_attn.value.bias
        , %para525 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.4.attention.output.dense.weight
        , %para526 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.4.attention.output.dense.bias
        , %para527 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.4.attention.output.layer_norm.gamma
        , %para528 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.4.attention.output.layer_norm.beta
        , %para529 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.4.intermediate.dense.weight
        , %para530 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.4.intermediate.dense.bias
        , %para531 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.4.output.dense.weight
        , %para532 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.4.output.dense.bias
        , %para533 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.4.output.layer_norm.gamma
        , %para534 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.4.output.layer_norm.beta
        , %para535 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.5.attention.self_attn.query.weight
        , %para536 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.5.attention.self_attn.query.bias
        , %para537 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.5.attention.self_attn.key.weight
        , %para538 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.5.attention.self_attn.key.bias
        , %para539 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.5.attention.self_attn.value.weight
        , %para540 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.5.attention.self_attn.value.bias
        , %para541 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.5.attention.output.dense.weight
        , %para542 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.5.attention.output.dense.bias
        , %para543 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.5.attention.output.layer_norm.gamma
        , %para544 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.5.attention.output.layer_norm.beta
        , %para545 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.5.intermediate.dense.weight
        , %para546 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.5.intermediate.dense.bias
        , %para547 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.5.output.dense.weight
        , %para548 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.5.output.dense.bias
        , %para549 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.5.output.layer_norm.gamma
        , %para550 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.5.output.layer_norm.beta
        , %para551 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.6.attention.self_attn.query.weight
        , %para552 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.6.attention.self_attn.query.bias
        , %para553 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.6.attention.self_attn.key.weight
        , %para554 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.6.attention.self_attn.key.bias
        , %para555 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.6.attention.self_attn.value.weight
        , %para556 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.6.attention.self_attn.value.bias
        , %para557 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.6.attention.output.dense.weight
        , %para558 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.6.attention.output.dense.bias
        , %para559 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.6.attention.output.layer_norm.gamma
        , %para560 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.6.attention.output.layer_norm.beta
        , %para561 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.6.intermediate.dense.weight
        , %para562 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.6.intermediate.dense.bias
        , %para563 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.6.output.dense.weight
        , %para564 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.6.output.dense.bias
        , %para565 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.6.output.layer_norm.gamma
        , %para566 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.6.output.layer_norm.beta
        , %para567 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.7.attention.self_attn.query.weight
        , %para568 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.7.attention.self_attn.query.bias
        , %para569 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.7.attention.self_attn.key.weight
        , %para570 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.7.attention.self_attn.key.bias
        , %para571 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.7.attention.self_attn.value.weight
        , %para572 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.7.attention.self_attn.value.bias
        , %para573 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.7.attention.output.dense.weight
        , %para574 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.7.attention.output.dense.bias
        , %para575 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.7.attention.output.layer_norm.gamma
        , %para576 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.7.attention.output.layer_norm.beta
        , %para577 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.7.intermediate.dense.weight
        , %para578 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.7.intermediate.dense.bias
        , %para579 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.7.output.dense.weight
        , %para580 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.7.output.dense.bias
        , %para581 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.7.output.layer_norm.gamma
        , %para582 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.7.output.layer_norm.beta
        , %para583 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.8.attention.self_attn.query.weight
        , %para584 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.8.attention.self_attn.query.bias
        , %para585 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.8.attention.self_attn.key.weight
        , %para586 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.8.attention.self_attn.key.bias
        , %para587 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.8.attention.self_attn.value.weight
        , %para588 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.8.attention.self_attn.value.bias
        , %para589 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.8.attention.output.dense.weight
        , %para590 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.8.attention.output.dense.bias
        , %para591 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.8.attention.output.layer_norm.gamma
        , %para592 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.8.attention.output.layer_norm.beta
        , %para593 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.8.intermediate.dense.weight
        , %para594 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.8.intermediate.dense.bias
        , %para595 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.8.output.dense.weight
        , %para596 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.8.output.dense.bias
        , %para597 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.8.output.layer_norm.gamma
        , %para598 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.8.output.layer_norm.beta
        , %para599 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.9.attention.self_attn.query.weight
        , %para600 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.9.attention.self_attn.query.bias
        , %para601 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.9.attention.self_attn.key.weight
        , %para602 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.9.attention.self_attn.key.bias
        , %para603 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.9.attention.self_attn.value.weight
        , %para604 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.9.attention.self_attn.value.bias
        , %para605 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.9.attention.output.dense.weight
        , %para606 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.9.attention.output.dense.bias
        , %para607 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.9.attention.output.layer_norm.gamma
        , %para608 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.9.attention.output.layer_norm.beta
        , %para609 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.9.intermediate.dense.weight
        , %para610 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.9.intermediate.dense.bias
        , %para611 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.9.output.dense.weight
        , %para612 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.9.output.dense.bias
        , %para613 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.9.output.layer_norm.gamma
        , %para614 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.9.output.layer_norm.beta
        , %para615 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.10.attention.self_attn.query.weight
        , %para616 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.10.attention.self_attn.query.bias
        , %para617 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.10.attention.self_attn.key.weight
        , %para618 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.10.attention.self_attn.key.bias
        , %para619 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.10.attention.self_attn.value.weight
        , %para620 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.10.attention.self_attn.value.bias
        , %para621 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.10.attention.output.dense.weight
        , %para622 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.10.attention.output.dense.bias
        , %para623 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.10.attention.output.layer_norm.gamma
        , %para624 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.10.attention.output.layer_norm.beta
        , %para625 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.10.intermediate.dense.weight
        , %para626 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.10.intermediate.dense.bias
        , %para627 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.10.output.dense.weight
        , %para628 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.10.output.dense.bias
        , %para629 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.10.output.layer_norm.gamma
        , %para630 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.10.output.layer_norm.beta
        , %para631 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.11.attention.self_attn.query.weight
        , %para632 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.11.attention.self_attn.query.bias
        , %para633 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.11.attention.self_attn.key.weight
        , %para634 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.11.attention.self_attn.key.bias
        , %para635 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.11.attention.self_attn.value.weight
        , %para636 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.11.attention.self_attn.value.bias
        , %para637 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.encoder.layer.11.attention.output.dense.weight
        , %para638 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.11.attention.output.dense.bias
        , %para639 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.11.attention.output.layer_norm.gamma
        , %para640 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.11.attention.output.layer_norm.beta
        , %para641 : Ref[Tensor(F32)][3072, 768]    # moment2.ques_channel.encoder.layer.11.intermediate.dense.weight
        , %para642 : Ref[Tensor(F32)][3072]    # moment2.ques_channel.encoder.layer.11.intermediate.dense.bias
        , %para643 : Ref[Tensor(F32)][768, 3072]    # moment2.ques_channel.encoder.layer.11.output.dense.weight
        , %para644 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.11.output.dense.bias
        , %para645 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.11.output.layer_norm.gamma
        , %para646 : Ref[Tensor(F32)][768]    # moment2.ques_channel.encoder.layer.11.output.layer_norm.beta
        , %para647 : Ref[Tensor(F32)][768, 768]    # moment2.ques_channel.pooler.dense.weight
        , %para648 : Ref[Tensor(F32)][768]    # moment2.ques_channel.pooler.dense.bias
        , %para649 : Ref[Tensor(F32)][512, 768]    # moment2.san.0.ff_image.weight
        , %para650 : Ref[Tensor(F32)][512]    # moment2.san.0.ff_image.bias
        , %para651 : Ref[Tensor(F32)][512, 768]    # moment2.san.0.ff_ques.weight
        , %para652 : Ref[Tensor(F32)][512]    # moment2.san.0.ff_ques.bias
        , %para653 : Ref[Tensor(F32)][1, 512]    # moment2.san.0.ff_attention.weight
        , %para654 : Ref[Tensor(F32)][1]    # moment2.san.0.ff_attention.bias
        , %para655 : Ref[Tensor(F32)][17625, 768]    # moment2.mlp.1.weight
        , %para656 : Ref[Tensor(F32)][17625]    # moment2.mlp.1.bias
        , %para657 : Ref[Tensor(F32)][]    # learning_rate
    ) {

#------------------------> 0
    %1 = FuncGraph::fg_113(%para1, %para2, %para3)    #(Tensor(F64)[4, 128], Tensor(F64)[4, 17625], Tensor(F64)[4, 3, 224, 224])    # fg_113=construct.113 #scope: Default
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(66)/#[CNode]117
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(66)/#[CNode]118
}
# order:
#   1: construct_wrapper.112:[CNode]117{[0]: ValueNode<FuncGraph> construct.113, [1]: q, [2]: a, [3]: img}
#   2: construct_wrapper.112:[CNode]118{[0]: ValueNode<Primitive> Return, [1]: [CNode]117}


# [No.2] construct.113
# In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(62)/
funcgraph fg_113[fg_112](
        %para658 : Tensor(F64)[4, 128]    # q
        , %para659 : Tensor(F64)[4, 17625]    # a
        , %para660 : Tensor(F64)[4, 3, 224, 224]    # img
    ) {

#------------------------> 1
    %1 = FuncGraph::fg_114(%para658, %para659, %para660)    #(Tensor(F64)[4, 128], Tensor(F64)[4, 17625], Tensor(F64)[4, 3, 224, 224])    # fg_114=construct.114 #scope: Default
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(63)/#loss
    %2 = FuncGraph::fg_119(%para658, %para660)    #(Tensor(F64)[4, 128], Tensor(F64)[4, 3, 224, 224])    # fg_119=construct.119 #scope: Default
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(64)/#out
    %3 = FuncGraph::fg_120(%2, %para659)    #(Undefined, Tensor(F64)[4, 17625])    # fg_120=batch_accuracy.120 #scope: Default
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(65)/#accuracy
    %4 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%1, %3)    #(Undefined, Undefined) #scope: Default
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(66)/#[CNode]121
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(66)/#[CNode]122
}
# order:
#   1: construct.113:loss{[0]: ValueNode<FuncGraph> construct.114, [1]: q, [2]: a, [3]: img}
#   2: construct.113:out{[0]: ValueNode<FuncGraph> construct.119, [1]: q, [2]: img}
#   3: construct.113:accuracy{[0]: ValueNode<FuncGraph> batch_accuracy.120, [1]: out, [2]: a}
#   4: construct.113:[CNode]121{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: loss, [2]: accuracy}
#   5: construct.113:[CNode]122{[0]: ValueNode<Primitive> Return, [1]: [CNode]121}


# [No.3] construct.114
# In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(40)/
funcgraph fg_114[fg_112](
        %para661 : Tensor(F64)[4, 128]    # q
        , %para662 : Tensor(F64)[4, 17625]    # a
        , %para663 : Tensor(F64)[4, 3, 224, 224]    # img
    ) {

#------------------------> 2
    %1 = FuncGraph::fg_115(%para661, %para662, %para663)    #(Tensor(F64)[4, 128], Tensor(F64)[4, 17625], Tensor(F64)[4, 3, 224, 224])    # fg_115=construct.115 #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(42)/#loss
    %2 = ClassType() #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(43)/#[CNode]123
    %3 = ClassType() #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(43)/#[CNode]124
    %4 = %3(%1)    #(Undefined) #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(43)/#[CNode]125
    %5 = ClassType() #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(43)/#[CNode]126
    %6 = %5(%1)    #(Undefined) #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(43)/#[CNode]127
    %7 = %2(%4, %6, F32(1))    #(Undefined, Undefined, Undefined) #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(43)/#sens
    %8 = UnpackGraphPrimitive::UnpackGraph{prim_type=1}(FuncGraph::fg_115, %para661, %para662, %para663, %7)    #(Undefined, Tensor(F64)[4, 128], Tensor(F64)[4, 17625], Tensor(F64)[4, 3, 224, 224], Undefined)    # fg_115=construct.115 #scope: Default
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(44)/#grads
    %9 = Primitive::MakeTuple{prim_type=1}(%para4, %para5, %para6, %para7, %para8, %para9, %para10, %para11, %para12, %para13, %para14, %para15, %para16, %para17, %para18, %para19, %para20, %para21, %para22, %para23, %para24, %para25, %para26, %para27, %para28, %para29, %para30, %para31, %para32, %para33, %para34, %para35, %para36, %para37, %para38, %para39, %para40, %para41, %para42, %para43, %para44, %para45, %para46, %para47, %para48, %para49, %para50, %para51, %para52, %para53, %para54, %para55, %para56, %para57, %para58, %para59, %para60, %para61, %para62, %para63, %para64, %para65, %para66, %para67, %para68, %para69, %para70, %para71, %para72, %para73, %para74, %para75, %para76, %para77, %para78, %para79, %para80, %para81, %para82, %para83, %para84, %para85, %para86, %para87, %para88, %para89, %para90, %para91, %para92, %para93, %para94, %para95, %para96, %para97, %para98, %para99, %para100, %para101, %para102, %para103, %para104, %para105, %para106, %para107, %para108, %para109, %para110, %para111, %para112, %para113, %para114, %para115, %para116, %para117, %para118, %para119, %para120, %para121, %para122, %para123, %para124, %para125, %para126, %para127, %para128, %para129, %para130, %para131, %para132, %para133, %para134, %para135, %para136, %para137, %para138, %para139, %para140, %para141, %para142, %para143, %para144, %para145, %para146, %para147, %para148, %para149, %para150, %para151, %para152, %para153, %para154, %para155, %para156, %para157, %para158, %para159, %para160, %para161, %para162, %para163, %para164, %para165, %para166, %para167, %para168, %para169, %para170, %para171, %para172, %para173, %para174, %para175, %para176, %para177, %para178, %para179, %para180, %para181, %para182, %para183, %para184, %para185, %para186, %para187, %para188, %para189, %para190, %para191, %para192, %para193, %para194, %para195, %para196, %para197, %para198, %para199, %para200, %para201, %para202, %para203, %para204, %para205, %para206, %para207, %para208, %para209, %para210, %para211, %para212, %para213, %para214, %para215, %para216, %para217, %para218, %para219, %para220)    #(Ref[Tensor(F32)][64, 3, 3, 3], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][128, 64, 3, 3], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][256, 128, 3, 3], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][768, 256, 3, 3], Ref[Tensor(F32)][30522, 768], Ref[Tensor(F32)][512, 768], Ref[Tensor(F32)][2, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][3072, 768], Ref[Tensor(F32)][3072], Ref[Tensor(F32)][768, 3072], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][768, 768], Ref[Tensor(F32)][768], Ref[Tensor(F32)][512, 768], Ref[Tensor(F32)][512], Ref[Tensor(F32)][512, 768], Ref[Tensor(F32)][512], Ref[Tensor(F32)][1, 512], Ref[Tensor(F32)][1], Ref[Tensor(F32)][17625, 768], Ref[Tensor(F32)][17625]) #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(41)/#[CNode]128
    %10 = DoSignaturePrimitive::S-Prim-grad{prim_type=1}(%8, %9)    #(Undefined, Undefined) #scope: Default
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(44)/#grads
    %11 = %10(%para661, %para662, %para663, %7)    #(Tensor(F64)[4, 128], Tensor(F64)[4, 17625], Tensor(F64)[4, 3, 224, 224], Undefined) #scope: Default
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(44)/#grads
    %12 = FuncGraph::fg_129(%11)    #(Undefined)    # fg_129=construct.129 #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(45)/#[CNode]130
    %13 = DoSignaturePrimitive::S-Prim-Depend{prim_type=1}[side_effect_propagate=I64(1)](%1, %12)    #(Undefined, Undefined) #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(45)/#[CNode]131
    Primitive::Return{prim_type=1}(%13)    #(Undefined) #scope: Default/loss_train_net-TrainOneStepCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(45)/#[CNode]132
}
# order:
#   1: construct.114:loss{[0]: ValueNode<FuncGraph> construct.115, [1]: q, [2]: a, [3]: img}
#   2: construct.114:[CNode]123{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.Fill'}
#   3: construct.114:[CNode]124{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.DType'}
#   4: construct.114:[CNode]125{[0]: [CNode]124, [1]: loss}
#   5: construct.114:[CNode]126{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.Shape'}
#   6: construct.114:[CNode]127{[0]: [CNode]126, [1]: loss}
#   7: construct.114:sens{[0]: [CNode]123, [1]: [CNode]125, [2]: [CNode]127, [3]: ValueNode<FP32Imm> 1.000000}
#   8: construct.114:grads{[0]: ValueNode<UnpackGraphPrimitive> UnpackGraph, [1]: ValueNode<FuncGraph> construct.115, [2]: q, [3]: a, [4]: img, [5]: sens}
#   9: construct.114:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-grad, [1]: grads, [2]: [CNode]128}
#  10: construct.114:grads{[0]: grads, [1]: q, [2]: a, [3]: img, [4]: sens}
#  11: construct.114:[CNode]130{[0]: ValueNode<FuncGraph> construct.129, [1]: grads}
#  12: construct.114:[CNode]131{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Depend, [1]: loss, [2]: [CNode]130}
#  13: construct.114:[CNode]132{[0]: ValueNode<Primitive> Return, [1]: [CNode]131}


# [No.4] construct.115
# In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(24)/
funcgraph fg_115(
        %para664 : Tensor(F64)[4, 128]    # q
        , %para665 : Tensor(F64)[4, 17625]    # a
        , %para666 : Tensor(F64)[4, 3, 224, 224]    # img
    ) {
    %1 : NoneType = FuncGraph::fg_119(%para664, %para666)    #(Tensor(F64)[4, 128], Tensor(F64)[4, 3, 224, 224])    # fg_119=construct.119 #scope: Default/loss_net-WithLossCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(25)/#out

#------------------------> 3
    %2 = FuncGraph::fg_116(%1, %para665)    #(NoneType, Tensor(F64)[4, 17625])    # fg_116=construct.116 #scope: Default/loss_net-WithLossCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(26)/#loss
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/loss_net-WithLossCell
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(27)/#[CNode]133
}
# order:
#   1: construct.115:out{[0]: ValueNode<FuncGraph> construct.119, [1]: q, [2]: img}
#   2: construct.115:loss{[0]: ValueNode<FuncGraph> construct.116, [1]: out, [2]: a}
#   3: construct.115:[CNode]133{[0]: ValueNode<Primitive> Return, [1]: loss}


# [No.5] construct.116
# In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(7)/
funcgraph fg_116(
        %para667 : NoneType    # logits
        , %para668 : Tensor(F64)[4, 17625]    # label
    ) {

#------------------------> 4
    %1 = ClassType(%para667)    #(NoneType) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(8)/#[CNode]134
    %2 = Primitive::getattr{prim_type=1}(%1, "astype")    #(Undefined, Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(8)/#[CNode]135
    %3 = %2(F64)    #(Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(8)/#logits
    %4 = DoSignaturePrimitive::S-Prim-LogSoftmax{prim_type=1}[axis=I64(0)](%3)    #(Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(10)/#[CNode]136
    %5 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(%4)    #(Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(10)/#nll
    %6 = ClassType(%para668)    #(Tensor(F64)[4, 17625]) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(9)/#[CNode]137
    %7 = Primitive::getattr{prim_type=1}(%6, "astype")    #(Undefined, Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(9)/#[CNode]138
    %8 = %7(F64)    #(Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(9)/#label
    %9 = DoSignaturePrimitive::S-Prim-mul{prim_type=1}(%5, %8)    #(Undefined, Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(11)/#[CNode]139
    %10 = DoSignaturePrimitive::S-Prim-div{prim_type=1}(%9, I64(10))    #(Undefined, Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(11)/#[CNode]140
    %11 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%10)    #(Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(11)/#[CNode]141
    %12 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}("axis")    #(Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(11)/#[CNode]142
    %13 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(I64(1))    #(Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(11)/#[CNode]143
    %14 = DoSignaturePrimitive::S-Prim-make_dict{prim_type=1}(%12, %13)    #(Undefined, Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(11)/#[CNode]144
    %15 = UnpackCall::unpack_call(DoSignaturePrimitive::S-Prim-ReduceSum{prim_type=1}[input_names=["input_x", "axis"], output_names=["y"], keep_dims=Bool(0)], %11, %14)    #(Undefined, Undefined, Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(11)/#[CNode]145
    %16 = Primitive::getattr{prim_type=1}(%15, "mean")    #(Undefined, Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(11)/#[CNode]146
    %17 = %16() #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(11)/#loss
    %18 = FuncGraph::fg_147(%17)    #(Undefined)    # fg_147=get_loss.147 #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(12)/#[CNode]148
    Primitive::Return{prim_type=1}(%18)    #(Undefined) #scope: Default/loss_net-WithLossCell/_loss_fn-NLLLoss
      # In file C:\Users\11314\AppData\Local\Temp\ipykernel_10100\3026731931.py(12)/#[CNode]149
}
# order:
#   1: construct.116:[CNode]134{[0]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor', [1]: logits}
#   2: construct.116:[CNode]135{[0]: ValueNode<Primitive> getattr, [1]: [CNode]134, [2]: ValueNode<StringImm> astype}
#   3: construct.116:logits{[0]: [CNode]135, [1]: ValueNode<Float> Float64}
#   4: construct.116:[CNode]137{[0]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor', [1]: label}
#   5: construct.116:[CNode]138{[0]: ValueNode<Primitive> getattr, [1]: [CNode]137, [2]: ValueNode<StringImm> astype}
#   6: construct.116:label{[0]: [CNode]138, [1]: ValueNode<Float> Float64}
#   7: construct.116:[CNode]136{[0]: ValueNode<DoSignaturePrimitive> S-Prim-LogSoftmax, [1]: logits}
#   8: construct.116:nll{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: [CNode]136}
#   9: construct.116:[CNode]139{[0]: ValueNode<DoSignaturePrimitive> S-Prim-mul, [1]: nll, [2]: label}
#  10: construct.116:[CNode]140{[0]: ValueNode<DoSignaturePrimitive> S-Prim-div, [1]: [CNode]139, [2]: ValueNode<Int64Imm> 10}
#  11: construct.116:[CNode]141{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]140}
#  12: construct.116:[CNode]142{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<StringImm> axis}
#  13: construct.116:[CNode]143{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<Int64Imm> 1}
#  14: construct.116:[CNode]144{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_dict, [1]: [CNode]142, [2]: [CNode]143}
#  15: construct.116:[CNode]145{[0]: ValueNode<UnpackCall> unpack_call, [1]: ValueNode<DoSignaturePrimitive> S-Prim-ReduceSum, [2]: [CNode]141, [3]: [CNode]144}
#  16: construct.116:[CNode]146{[0]: ValueNode<Primitive> getattr, [1]: [CNode]145, [2]: ValueNode<StringImm> mean}
#  17: construct.116:loss{[0]: [CNode]146}
#  18: construct.116:[CNode]148{[0]: ValueNode<FuncGraph> get_loss.147, [1]: loss}
#  19: construct.116:[CNode]149{[0]: ValueNode<Primitive> Return, [1]: [CNode]148}


#===============================================================================
# num of function graphs in stack: 5
