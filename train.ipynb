{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75afd032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "import mindspore\n",
    "from mindspore import Tensor, nn, Model, context\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "from mindspore import ops\n",
    "from mindspore.ops import functional as F\n",
    "from mindspore.ops import composite as C\n",
    "from mindspore.common.parameter import ParameterTuple\n",
    "from mindspore.train.callback import LossMonitor, CheckpointConfig, ModelCheckpoint, TimeMonitor\n",
    "from mindspore.nn import WithLossCell\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "import dataset\n",
    "import san\n",
    "import utils\n",
    "import mindspore.context as context\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "113c0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLLLoss(nn.LossBase):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(NLLLoss, self).__init__(reduction)\n",
    "        self.reduce_sum = ops.ReduceSum()\n",
    "        self.log_softmax = ops.LogSoftmax(axis=0)\n",
    "\n",
    "    def construct(self, logits, label):\n",
    "#         logits = Tensor(logits).astype(mindspore.float64)\n",
    "#         label = Tensor(label).astype(mindspore.float64)\n",
    "        nll = -self.log_softmax(logits)\n",
    "        loss = self.reduce_sum(nll * label / config.alter_ans_num, axis=1).mean()\n",
    "        return self.get_loss(loss)\n",
    "\n",
    "\n",
    "class WithLossCell(nn.Cell):\n",
    "    \"\"\"\n",
    "    The cell wrapped with NLL loss, for train only\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(WithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._loss_fn = NLLLoss()\n",
    "        self.net = model\n",
    "\n",
    "    def construct(self, q, a, img):\n",
    "        out = self.net(q, img)\n",
    "        loss = self._loss_fn(out, a)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class TrainOneStepCell(nn.Cell):\n",
    "    def __init__(self, network, optimizer, sens=1.0):\n",
    "        super(TrainOneStepCell, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "        self.network.add_flags(defer_inline=True)\n",
    "        self.weights = ParameterTuple(network.trainable_params())\n",
    "        self.optimizer = optimizer\n",
    "        self.grad = C.GradOperation(get_by_list=True)\n",
    "        self.sens = sens\n",
    "\n",
    "    def construct(self, q, a, img):\n",
    "        weights = self.weights\n",
    "        loss = self.network(q, a, img)\n",
    "        sens = ops.Fill()(ops.DType()(loss), ops.Shape()(loss), self.sens)\n",
    "        grads = self.grad(self.network, weights)(q, a, img, sens)\n",
    "        return F.depend(loss, self.optimizer(grads))\n",
    "\n",
    "\n",
    "class TrainNetWrapper(nn.Cell):\n",
    "    \"\"\"\n",
    "    The highest level train cell. (use it directly)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(TrainNetWrapper, self).__init__(auto_prefix=False)\n",
    "        self.net = model\n",
    "\n",
    "        self.loss_net = WithLossCell(self.net)#need q, a, img\n",
    "        optimizer = nn.Adam(params=self.net.trainable_params(), learning_rate=config.initial_lr)\n",
    "\n",
    "        self.loss_train_net = TrainOneStepCell(self.loss_net, optimizer)\n",
    "\n",
    "    def construct(self, q, a, img):\n",
    "        loss = self.loss_train_net(q, a, img)\n",
    "        out = self.net(q, img)\n",
    "        accuracy = utils.batch_accuracy(out, a)\n",
    "        return loss, accuracy\n",
    "\n",
    "\n",
    "class OutLossAccuracyWrapper(nn.Cell):\n",
    "    \"\"\"\n",
    "    The highest level cell for evaluation, wrapped with NLL Loss and accuracy. (use it directly)\n",
    "    \n",
    "    Output:\n",
    "        output: a Tensor of shape (batch_size, config.max_answers) (logits)\n",
    "        loss: a scalar value\n",
    "        accuracy: a Tensor of shape (batch_size, 1)\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(OutLossAccuracyWrapper, self).__init__()\n",
    "        self.net = model\n",
    "        self._loss_fn = NLLLoss()\n",
    "\n",
    "    def construct(self, q, a, img):\n",
    "        output = self.net(q, img)\n",
    "        loss = self._loss_fn(output, a)\n",
    "        accuracy = utils.batch_accuracy(output, a)\n",
    "        return output, loss, accuracy\n",
    "\n",
    "\n",
    "def run(net, loader, epoch, train=False, prefix=''):\n",
    "    \"\"\" Run an epoch over the given loader \"\"\"\n",
    "    arg_max = ops.Argmax(axis=1, output_type=mindspore.int32)\n",
    "    cat = ops.Concat(axis=0)\n",
    "    losses = []\n",
    "    accs = []\n",
    "\n",
    "    if train:\n",
    "        net.set_train(True)\n",
    "        print(\"Start training...\")\n",
    "    else:\n",
    "        print(\"Start evaluating...\")\n",
    "        net.set_train(False)\n",
    "        answers = []\n",
    "\n",
    "    tq = tqdm(loader, desc='{} EPOCH{:02d}'.format(prefix, epoch), ncols=0, total=math.ceil(len(loader.source) / config.batch_size))\n",
    "    for q, a, img in tq:\n",
    "        q = Tensor(q).astype(mindspore.float64)\n",
    "        a = Tensor(a).astype(mindspore.float64)\n",
    "        img = Tensor(img).astype(mindspore.float64)\n",
    "        if train:\n",
    "            loss, acc = net(q, a, img)\n",
    "        else:\n",
    "            output, loss, acc = net(q, a, img)\n",
    "            answer = arg_max(output)\n",
    "            answers.append(answer.view(-1))\n",
    "        losses.append(loss.view(-1))\n",
    "        accs.append(acc.view(-1))\n",
    "    answers = list(map(int, list(cat(answers).asnumpy())))\n",
    "    accs = list(cat(accs).asnumpy().astype(float))\n",
    "    if not train:\n",
    "        return answers, accs\n",
    "    else:\n",
    "        return losses, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02538132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be saved to logs\\2022-06-26_14:39:34.ckpt\n",
      "Generating answers vocab...\n",
      "Answers vocab is generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(10100:476,MainProcess):2022-06-26-14:40:08.892.992 [mindspore\\train\\serialization.py:581] Remove parameter prefix name: bert., continue to load.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers vocab...\n",
      "Answers vocab is generated\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # if config.device == 'GPU': os.environ['CUDA_VISIBLE_DEVICES'] = '1' # select GPU if necessary\n",
    "    # context.set_context(mode=context.PYNATIVE_MODE, device_target=config.device)\n",
    "#     context.set_context(mode=context.GRAPH_MODE, save_graphs=False, device_target='Ascend')\n",
    "\n",
    "    name = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "    target_name = os.path.join('logs', '{}.ckpt'.format(name))\n",
    "    print('The model will be saved to {}'.format(target_name))\n",
    "\n",
    "    val_loader = dataset.get_loader(val=True)\n",
    "\n",
    "    model = san.SANModel()\n",
    "\n",
    "    # if config.pretrained:\n",
    "    #     pretrain_params = load_checkpoint(config.pretrained_model_path)\n",
    "    #     if pretrain_params is not None:\n",
    "    #         print(\"Successfully loaded pretrained model from {}.\".format(config.pretrained_model_path))\n",
    "    #     load_param_into_net(SAN, pretrain_params)\n",
    "\n",
    "    train_net = TrainNetWrapper(model) # for train\n",
    "    eval_net = OutLossAccuracyWrapper(model) # for evaluation\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        train_loader = dataset.get_loader(train=True)\n",
    "        \n",
    "        \"\"\"\n",
    "        Wrapped train with `tqdm`\n",
    "        \"\"\"\n",
    "        run(train_net, train_loader,train=True, prefix='train', epoch=epoch)\n",
    "        answers, accs = run(eval_net, val_loader, train=False, prefix='val', epoch=epoch)\n",
    "        \n",
    "        # Calculate the validate accuracy mean of each batch\n",
    "        total_acc = 0\n",
    "        for acc_list in accs:\n",
    "            total_acc += sum(acc_list)\n",
    "        total_acc /= len(accs)*len(accs[0])\n",
    "\n",
    "        results = {\n",
    "            'name': name,\n",
    "            # 'tracker': tracker.to_dict(),\n",
    "            'accuracy': total_acc,\n",
    "            'eval': {\n",
    "                'answers': answers,\n",
    "                'accuracies': accs\n",
    "            },\n",
    "            'vocab': train_loader.source.ans_to_idx,\n",
    "        }\n",
    "\n",
    "        # Save model as CKPT every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            mindspore.save_checkpoint(train_net.net, ckpt_file_name=os.path.join('logs', '{}.ckpt'.format(name)))\n",
    "        \n",
    "        # Save train meta info as JSON\n",
    "        with open(os.path.join('logs', 'TrainRecord_{}.json'.format(name)), 'w') as fp:\n",
    "            fp.write(json.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcfa6c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'mindspore.common.tensor.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "img = np.array([[1,2,3],[4,5,6]])\n",
    "print(type(img))\n",
    "img = Tensor(img).astype(mindspore.float64)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385869f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
