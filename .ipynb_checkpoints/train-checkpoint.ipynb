{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75afd032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "import mindspore\n",
    "from mindspore import Tensor, nn, Model, context\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "from mindspore import ops\n",
    "from mindspore.ops import functional as F\n",
    "from mindspore.ops import composite as C\n",
    "from mindspore.common.parameter import ParameterTuple\n",
    "from mindspore.train.callback import LossMonitor, CheckpointConfig, ModelCheckpoint, TimeMonitor\n",
    "from mindspore.nn import WithLossCell\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "import dataset\n",
    "import san\n",
    "import utils\n",
    "import mindspore.context as context\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "113c0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLLLoss(nn.LossBase):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(NLLLoss, self).__init__(reduction)\n",
    "        self.reduce_sum = ops.ReduceSum()\n",
    "        self.log_softmax = ops.LogSoftmax(axis=0)\n",
    "\n",
    "    def construct(self, logits, label):\n",
    "#         logits = Tensor(logits).astype(mindspore.float64)\n",
    "#         label = Tensor(label).astype(mindspore.float64)\n",
    "        nll = -self.log_softmax(logits)\n",
    "        loss = self.reduce_sum(nll * label / config.alter_ans_num, axis=1).mean()\n",
    "        return self.get_loss(loss)\n",
    "\n",
    "\n",
    "class WithLossCell(nn.Cell):\n",
    "    \"\"\"\n",
    "    The cell wrapped with NLL loss, for train only\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(WithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._loss_fn = NLLLoss()\n",
    "        self.net = model\n",
    "\n",
    "    def construct(self, q, a, img):\n",
    "        out = self.net(q, img)\n",
    "        loss = self._loss_fn(out, a)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class TrainOneStepCell(nn.Cell):\n",
    "    def __init__(self, network, optimizer, sens=1.0):\n",
    "        super(TrainOneStepCell, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "        self.network.add_flags(defer_inline=True)\n",
    "        self.weights = ParameterTuple(network.trainable_params())\n",
    "        self.optimizer = optimizer\n",
    "        self.grad = C.GradOperation(get_by_list=True)\n",
    "        self.sens = sens\n",
    "\n",
    "    def construct(self, q, a, img):\n",
    "        weights = self.weights\n",
    "        loss = self.network(q, a, img)\n",
    "        sens = ops.Fill()(ops.DType()(loss), ops.Shape()(loss), self.sens)\n",
    "        grads = self.grad(self.network, weights)(q, a, img, sens)\n",
    "        return F.depend(loss, self.optimizer(grads))\n",
    "\n",
    "\n",
    "class TrainNetWrapper(nn.Cell):\n",
    "    \"\"\"\n",
    "    The highest level train cell. (use it directly)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(TrainNetWrapper, self).__init__(auto_prefix=False)\n",
    "        self.net = model\n",
    "\n",
    "        self.loss_net = WithLossCell(self.net)#need q, a, img\n",
    "        optimizer = nn.Adam(params=self.net.trainable_params(), learning_rate=config.initial_lr)\n",
    "\n",
    "        self.loss_train_net = TrainOneStepCell(self.loss_net, optimizer)\n",
    "\n",
    "    def construct(self, q, a, img):\n",
    "        loss = self.loss_train_net(q, a, img)\n",
    "        out = self.net(q, img)\n",
    "        accuracy = utils.batch_accuracy(out, a)\n",
    "        return loss, accuracy\n",
    "\n",
    "\n",
    "class OutLossAccuracyWrapper(nn.Cell):\n",
    "    \"\"\"\n",
    "    The highest level cell for evaluation, wrapped with NLL Loss and accuracy. (use it directly)\n",
    "    \n",
    "    Output:\n",
    "        output: a Tensor of shape (batch_size, config.max_answers) (logits)\n",
    "        loss: a scalar value\n",
    "        accuracy: a Tensor of shape (batch_size, 1)\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(OutLossAccuracyWrapper, self).__init__()\n",
    "        self.net = model\n",
    "        self._loss_fn = NLLLoss()\n",
    "\n",
    "    def construct(self, q, a, img):\n",
    "        output = self.net(q, img)\n",
    "        loss = self._loss_fn(output, a)\n",
    "        accuracy = utils.batch_accuracy(output, a)\n",
    "        return output, loss, accuracy\n",
    "\n",
    "\n",
    "def run(net, loader, epoch, train=False, prefix=''):\n",
    "    \"\"\" Run an epoch over the given loader \"\"\"\n",
    "    arg_max = ops.Argmax(axis=1, output_type=mindspore.int32)\n",
    "    cat = ops.Concat(axis=0)\n",
    "    losses = []\n",
    "    accs = []\n",
    "\n",
    "    if train:\n",
    "        net.set_train(True)\n",
    "        print(\"Start training...\")\n",
    "    else:\n",
    "        print(\"Start evaluating...\")\n",
    "        net.set_train(False)\n",
    "        answers = []\n",
    "\n",
    "    tq = tqdm(loader, desc='{} EPOCH{:02d}'.format(prefix, epoch), ncols=0, total=math.ceil(len(loader.source) / config.batch_size))\n",
    "    for q, a, img in tq:\n",
    "        q = Tensor(q).astype(mindspore.float64)\n",
    "        a = Tensor(a).astype(mindspore.float64)\n",
    "        img = Tensor(img).astype(mindspore.float64)\n",
    "        if train:\n",
    "            loss, acc = net(q, a, img)\n",
    "        else:\n",
    "            output, loss, acc = net(q, a, img)\n",
    "            answer = arg_max(output)\n",
    "            answers.append(answer.view(-1))\n",
    "        losses.append(loss.view(-1))\n",
    "        accs.append(acc.view(-1))\n",
    "    answers = list(map(int, list(cat(answers).asnumpy())))\n",
    "    accs = list(cat(accs).asnumpy().astype(float))\n",
    "    if not train:\n",
    "        return answers, accs\n",
    "    else:\n",
    "        return losses, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02538132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be saved to logs\\2022-06-26_14:35:29.ckpt\n",
      "Generating answers vocab...\n",
      "Answers vocab is generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(10100:476,MainProcess):2022-06-26-14:36:08.259.504 [mindspore\\train\\serialization.py:581] Remove parameter prefix name: bert., continue to load.\n",
      "[WARNING] ME(10100:476,MainProcess):2022-06-26-14:36:08.698.545 [mindspore\\nn\\loss\\loss.py:103] '_Loss' is deprecated from version 1.3 and will be removed in a future version, use 'LossBase' instead.\n",
      "[WARNING] ME(10100:476,MainProcess):2022-06-26-14:36:10.160.929 [mindspore\\nn\\loss\\loss.py:103] '_Loss' is deprecated from version 1.3 and will be removed in a future version, use 'LossBase' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers vocab...\n",
      "Answers vocab is generated\n",
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train EPOCH00:   0% 0/5768 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndentationError",
     "evalue": "There are incorrect indentations in definition or comment of function: 'NLLLoss.construct'. (1706211886.py, line 7)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\11314\\anaconda3\\envs\\vqa\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3457\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"C:\\Users\\11314\\AppData\\Local\\Temp\\ipykernel_10100\\1559790904.py\"\u001b[0m, line \u001b[0;32m30\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    run(train_net, train_loader,train=True, prefix='train', epoch=epoch)\n",
      "  File \u001b[0;32m\"C:\\Users\\11314\\AppData\\Local\\Temp\\ipykernel_10100\\1706211886.py\"\u001b[0m, line \u001b[0;32m111\u001b[0m, in \u001b[0;35mrun\u001b[0m\n    loss, acc = net(q, a, img)\n",
      "  File \u001b[0;32m\"C:\\Users\\11314\\anaconda3\\envs\\vqa\\lib\\site-packages\\mindspore\\nn\\cell.py\"\u001b[0m, line \u001b[0;32m386\u001b[0m, in \u001b[0;35m__call__\u001b[0m\n    out = self.compile_and_run(*inputs)\n",
      "  File \u001b[0;32m\"C:\\Users\\11314\\anaconda3\\envs\\vqa\\lib\\site-packages\\mindspore\\nn\\cell.py\"\u001b[0m, line \u001b[0;32m644\u001b[0m, in \u001b[0;35mcompile_and_run\u001b[0m\n    self.compile(*inputs)\n",
      "  File \u001b[0;32m\"C:\\Users\\11314\\anaconda3\\envs\\vqa\\lib\\site-packages\\mindspore\\nn\\cell.py\"\u001b[0m, line \u001b[0;32m631\u001b[0m, in \u001b[0;35mcompile\u001b[0m\n    _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode)\n",
      "  File \u001b[0;32m\"C:\\Users\\11314\\anaconda3\\envs\\vqa\\lib\\site-packages\\mindspore\\common\\api.py\"\u001b[0m, line \u001b[0;32m531\u001b[0m, in \u001b[0;35mcompile\u001b[0m\n    result = self._executor.compile(obj, args_list, phase, use_vm, self.queue_name)\n",
      "  File \u001b[0;32m\"C:\\Users\\11314\\anaconda3\\envs\\vqa\\lib\\site-packages\\mindspore\\_extends\\parse\\parser.py\"\u001b[0m, line \u001b[0;32m528\u001b[0m, in \u001b[0;35mparse\u001b[0m\n    raise idt_err\n",
      "  File \u001b[0;32m\"C:\\Users\\11314\\anaconda3\\envs\\vqa\\lib\\site-packages\\mindspore\\_extends\\parse\\parser.py\"\u001b[0m, line \u001b[0;32m522\u001b[0m, in \u001b[0;35mparse\u001b[0m\n    tree = asttokens.ASTTokens(src, parse=True).tree\n",
      "  File \u001b[0;32m\"C:\\Users\\11314\\anaconda3\\envs\\vqa\\lib\\site-packages\\asttokens\\asttokens.py\"\u001b[0m, line \u001b[0;32m47\u001b[0m, in \u001b[0;35m__init__\u001b[0m\n    self._tree = ast.parse(source_text, filename) if parse else tree\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\11314\\anaconda3\\envs\\vqa\\lib\\ast.py\"\u001b[1;36m, line \u001b[1;32m35\u001b[1;36m, in \u001b[1;35mparse\u001b[1;36m\u001b[0m\n\u001b[1;33m    return compile(source, filename, mode, PyCF_ONLY_AST)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\11314\\AppData\\Local\\Temp\\ipykernel_10100\\1706211886.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    def construct(self, logits, label):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m There are incorrect indentations in definition or comment of function: 'NLLLoss.construct'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # if config.device == 'GPU': os.environ['CUDA_VISIBLE_DEVICES'] = '1' # select GPU if necessary\n",
    "    # context.set_context(mode=context.PYNATIVE_MODE, device_target=config.device)\n",
    "#     context.set_context(mode=context.GRAPH_MODE, save_graphs=False, device_target='Ascend')\n",
    "\n",
    "    name = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "    target_name = os.path.join('logs', '{}.ckpt'.format(name))\n",
    "    print('The model will be saved to {}'.format(target_name))\n",
    "\n",
    "    val_loader = dataset.get_loader(val=True)\n",
    "\n",
    "    model = san.SANModel()\n",
    "\n",
    "    # if config.pretrained:\n",
    "    #     pretrain_params = load_checkpoint(config.pretrained_model_path)\n",
    "    #     if pretrain_params is not None:\n",
    "    #         print(\"Successfully loaded pretrained model from {}.\".format(config.pretrained_model_path))\n",
    "    #     load_param_into_net(SAN, pretrain_params)\n",
    "\n",
    "    train_net = TrainNetWrapper(model) # for train\n",
    "    eval_net = OutLossAccuracyWrapper(model) # for evaluation\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        train_loader = dataset.get_loader(train=True)\n",
    "        \n",
    "        \"\"\"\n",
    "        Wrapped train with `tqdm`\n",
    "        \"\"\"\n",
    "        run(train_net, train_loader,train=True, prefix='train', epoch=epoch)\n",
    "        answers, accs = run(eval_net, val_loader, train=False, prefix='val', epoch=epoch)\n",
    "        \n",
    "        # Calculate the validate accuracy mean of each batch\n",
    "        total_acc = 0\n",
    "        for acc_list in accs:\n",
    "            total_acc += sum(acc_list)\n",
    "        total_acc /= len(accs)*len(accs[0])\n",
    "\n",
    "        results = {\n",
    "            'name': name,\n",
    "            # 'tracker': tracker.to_dict(),\n",
    "            'accuracy': total_acc,\n",
    "            'eval': {\n",
    "                'answers': answers,\n",
    "                'accuracies': accs\n",
    "            },\n",
    "            'vocab': train_loader.source.ans_to_idx,\n",
    "        }\n",
    "\n",
    "        # Save model as CKPT every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            mindspore.save_checkpoint(train_net.net, ckpt_file_name=os.path.join('logs', '{}.ckpt'.format(name)))\n",
    "        \n",
    "        # Save train meta info as JSON\n",
    "        with open(os.path.join('logs', 'TrainRecord_{}.json'.format(name)), 'w') as fp:\n",
    "            fp.write(json.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8362396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'mindspore.common.tensor.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "img = np.array([[1,2,3],[4,5,6]])\n",
    "print(type(img))\n",
    "img = Tensor(img).astype(mindspore.float64)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852a918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
